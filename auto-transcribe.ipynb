{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c66eaaf-30ae-4649-b08b-8821d3bf8b2a",
   "metadata": {},
   "source": [
    "# Notebook to transcribe all files in directory via Watson Speech-To-Text service\n",
    "\n",
    "## TODO:\n",
    "  1) Connect to IBM Cloud Storage Bucket instead of local directory \n",
    "  2) Set up callbacks and asynch I/O for the transcriptions\n",
    "  3) Parallelize the transcription processing\n",
    "  4) Walk the JSONs produced in the transcription process and load them back into memory\n",
    "  5) Notebookify analyze.py, and scriptify the auto-transcribe notebook for easier use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d58ab98-afa4-4e53-aebb-13d65beea148",
   "metadata": {},
   "source": [
    "#### Customization variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e28d8f-4dad-464b-a6c3-d01dc21272d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "apikey = ''\n",
    "endpoint = ''\n",
    "content_type = 'audio/l16'\n",
    "file_type = '.wav'\n",
    "file_dir = 'static/audio/'\n",
    "transcription_dir = 'static/transcriptions/'\n",
    "model_name = 'en-US_NarrowbandModel'\n",
    "model_customization_id = ''\n",
    "language_customization_id = ''\n",
    "reference_transcriptions_file='static/transcriptions/reference-transcriptions.csv'\n",
    "stt_transcriptions_file='static/transcriptions/auto-transcriptions.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190b0f39-0605-4845-8763-466dcecc544a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Authentication is via IAM token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a7c55c-2d3b-45a0-8819-ee831c3ed9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from ibm_watson import SpeechToTextV1\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "authenticator = IAMAuthenticator(apikey)\n",
    "service = SpeechToTextV1(authenticator=authenticator)\n",
    "service.set_service_url(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991e67a6-6986-4876-931f-5e52302394a4",
   "metadata": {},
   "source": [
    "__service.list_models()__:\n",
    "Lists all models supported by the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d7d278-a28d-4329-a8a3-b7b30a7e4d71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = service.list_models().get_result()\n",
    "print(json.dumps(models, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cf47c5-9140-4ee8-8724-6cdaab1457f9",
   "metadata": {},
   "source": [
    "__service.list_language_models()__: Lists all the customized language models supported by the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772afd92-c3dd-44ba-ab9b-cfa7987490f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_models = service.list_language_models().get_result()\n",
    "print(json.dumps(language_models, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6e3f2b-2a33-4ffa-ac62-9e31b451ed4c",
   "metadata": {},
   "source": [
    "__service.get_model()__:\n",
    "This next method gets a specific, named model, from the service, provided it is supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3fd2c0-0abf-4cf1-8be4-bccce46e61d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = service.get_model(model_name).get_result()\n",
    "print(json.dumps(model, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed95164-86ae-4324-8c20-92f7d352ed3c",
   "metadata": {},
   "source": [
    "Using __pathlib.Path__, iterate through all the files in *file_dir* and append a dictionary of input file names matching *file_type* and output JSON file names matching the input file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dbb213-780d-4711-bb84-e4c1a59aae8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from os.path import dirname, join\n",
    "from pathlib import Path\n",
    "\n",
    "files = []\n",
    "basepath = Path(file_dir)\n",
    "basepath_child_items = basepath.iterdir()\n",
    "for item in basepath_child_items:\n",
    "    if item.is_file() and item.suffix == file_type:\n",
    "        files.append({'in_file': item.name,\n",
    "                      'out_file': item.name.replace(file_type,\n",
    "                                                    '.json')})\n",
    "print(json.dumps(files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909280b3-5a16-4d1b-bddf-084aa85f9313",
   "metadata": {},
   "source": [
    "**TODO**: For all file names in a list, access a IBM Cloud Object Storage service and retrieve the files, send it to the STT service, and upload the resulting JSON to the same IBM Cloud Object Storage service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557198b5-ac8f-4a98-ba05-8336acfccb89",
   "metadata": {},
   "source": [
    "#### Setting up the CSV export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e83404e-dde5-4de9-a354-e371a1d401d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriptions = []\n",
    "transcriptions.append({'file_name': 'Audio File Name',\n",
    "                       'model_name': 'Model name',\n",
    "                       'transcription': 'Transcription',\n",
    "                       'time_to_transcribe': 'Time to transcribe'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18bb4a9-c121-47c2-b1aa-4ad3316ebb0b",
   "metadata": {},
   "source": [
    "### Transcribe audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b23f12-b2ae-46ee-b841-5817c7dea9f4",
   "metadata": {},
   "source": [
    "For all files in the list created above, send the file in question to be transcribed by the Watson Speech-To-Text service, and dump the response to a JSON file in the *transcription_dir* that matches the file name of the audio file it matches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8258cafe-ba6e-4154-9e3c-2da9521d2d84",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Narrowband model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c201b8c-59b7-4d01-a42b-2721f8cd2d8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    print(f\"{join(file_dir, file['in_file'])} being transcribed.\")\n",
    "    \n",
    "    start = timer()\n",
    "    with open(join(file_dir, file['in_file']), 'rb') as audio_file:\n",
    "        narrowband_transcription_result = service.recognize(\n",
    "                audio=audio_file,\n",
    "                content=content_type,\n",
    "                timestamps=True,\n",
    "                speaker_labels=True,\n",
    "                end_of_phrase_silence_time=120.0,\n",
    "                split_transcript_at_phrase_end=False,\n",
    "                smart_formatting=True,\n",
    "                model=model_name).get_result()\n",
    "        \n",
    "        with open(join(join(transcription_dir, 'narrowband'), file['out_file']),\n",
    "                  'w') as transcript_file:\n",
    "            transcript_file.write(json.dumps(narrowband_transcription_result, indent=2))       \n",
    "    end = timer()\n",
    "    \n",
    "    for result in telephony_transcription_result['results']:\n",
    "        transcription = {'file_name': file['in_file'],\n",
    "                         'model_name': model,\n",
    "                         'transcription': result['alternatives'][0]['transcript'],\n",
    "                         'time_to_transcribe': (end - start)}\n",
    "        transcriptions.append(transcription)\n",
    "    print(f\"Telephony transcription complete in {(end - start)} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb8dbb2-8fc7-4c04-8288-5f69b3e51a5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Custom narrowband model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ab8993-a81a-447d-b6c5-928120d70c85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    print(f\"{join(file_dir, file['in_file'])} being transcribed.\")\n",
    " \n",
    "    start = timer()\n",
    "    with open(join(file_dir, file['in_file']), 'rb') as audio_file:\n",
    "        custom_narrowband_transcription_result = service.recognize(\n",
    "                audio=audio_file,\n",
    "                content=content_type,\n",
    "                timestamps=True,\n",
    "                speaker_labels=True,\n",
    "                end_of_phrase_silence_time=120.0,\n",
    "                split_transcript_at_phrase_end=False,\n",
    "                smart_formatting=True,\n",
    "                model=model_name,\n",
    "                language_customization_id=model_customization_id).get_result()\n",
    "        \n",
    "        with open(join(join(transcription_dir, 'custom_narrowband'), file['out_file']),\n",
    "                  'w') as transcript_file:\n",
    "            transcript_file.write(json.dumps(custom_narrowband_transcription_result, indent=2))\n",
    "    end = timer()\n",
    "    \n",
    "    for result in telephony_transcription_result['results']:\n",
    "        transcription = {'file_name': file['in_file'],\n",
    "                         'model_name': model,\n",
    "                         'transcription': result['alternatives'][0]['transcript'],\n",
    "                         'time_to_transcribe': (end - start)}\n",
    "        transcriptions.append(transcription)\n",
    "    print(f\"Telephony transcription complete in {(end - start)} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb15815-4275-42d7-bd29-477e5f60db1b",
   "metadata": {},
   "source": [
    "#### (BETA) next-gen telephony model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f342558c-0c4a-4479-bba1-de189d5902a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = 'en-US_Telephony'\n",
    "\n",
    "for file in files:\n",
    "    print(f\"{join(file_dir, file['in_file'])} being transcribed.\")\n",
    "    \n",
    "    start = timer()\n",
    "    with open(join(file_dir, file['in_file']), 'rb') as audio_file:\n",
    "        telephony_transcription_result = service.recognize(\n",
    "                audio=audio_file,\n",
    "                content=content_type,\n",
    "                timestamps=True,\n",
    "                speaker_labels=True,\n",
    "                end_of_phrase_silence_time=120.0,\n",
    "                split_transcript_at_phrase_end=False,\n",
    "                smart_formatting=True,\n",
    "                model=model).get_result()\n",
    "\n",
    "        with open(join(join(transcription_dir, 'telephony'), file['out_file']),\n",
    "                  'w') as transcript_file:\n",
    "            transcript_file.write(json.dumps(telephony_transcription_result, indent=2))\n",
    "            \n",
    "        audio_file.close()\n",
    "    end = timer()\n",
    "\n",
    "    for result in telephony_transcription_result['results']:\n",
    "        transcription = {'file_name': file['in_file'],\n",
    "                         'model_name': model,\n",
    "                         'transcription': result['alternatives'][0]['transcript'],\n",
    "                         'time_to_transcribe': (end - start)}\n",
    "        transcriptions.append(transcription)\n",
    "    print(f\"Telephony transcription complete in {(end - start)} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f919ac68-dd9f-4416-88cb-d322c6b74160",
   "metadata": {},
   "source": [
    "__(Optional)__: We write out the full `transcriptions` list as a JSON object to a file to prevent having to rerun all the transcriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0544023b-0944-4bde-9f56-41366894a663",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(join(transcription_dir, stt_transcriptions_file.replace('.csv', '.json')), 'w') as transcriptions_json:\n",
    "    transcriptions_json.write(f\"{json.dumps(transcriptions, indent=2)}\")\n",
    "\n",
    "print(f\"{json.dumps(transcriptions, indent=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff45dd67-9698-410f-bd78-08764f45b2c1",
   "metadata": {},
   "source": [
    "__(Optional)__: If you have a previous transcription session to load, use the below to open and read the transcriptions back into kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b8be87-45c9-47b9-867e-79a747bbf5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(transcriptions_dir, stt_transcriptions_file.replace('.csv', '.json')), 'rb') as transcriptions_json:\n",
    "    transcriptions = json.load(transcriptions_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdceea5d-8205-42f6-bd62-2dd38fac2b29",
   "metadata": {},
   "source": [
    "__TODO__: __(Optional)__: Walk transcription JSONs back into memory\n",
    "*Presently non-functional*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37b0288-a684-490f-8fd9-043ed502c05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files = []\n",
    "\n",
    "def transcribe(path):\n",
    "    transcriptions = []\n",
    "    transcription_basepath = Path(path)\n",
    "    transcription_basepath_child_items = transcription_basepath.iterdir()\n",
    "    print(json.dumps(transcription_basepath_child_items))\n",
    "    for item in transcription_basepath_child_items:\n",
    "        pass\n",
    "    return transcriptions\n",
    "\n",
    "transcriptions = transcribe(transcription_dir)\n",
    "print(json.dumps(transcriptions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d62eaf7-5939-48b0-99fc-d0bcce022289",
   "metadata": {},
   "source": [
    "We then translate the consolidated transcription output into comma-separated value notation and write it out to file to then be used with `analyze.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2c85de-6822-4f15-8184-2049d86dc442",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(transcription_dir, stt_transcriptions_file), 'w') as consolidated_csv:\n",
    "    for transcription in transcriptions:\n",
    "        consolidated_csv.write(','.join([transcription['file_name'],\n",
    "                                         transcription['model_name'],\n",
    "                                         transcription['transcription'],\n",
    "                                         str(transcription['time_to_transcribe']),\n",
    "                                         '\\n']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
